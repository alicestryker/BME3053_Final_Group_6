{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8190efd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports - DO NOT CHANGE\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cd34f76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeukemiaDetectionModel:\n",
    "    def __init__(self, target_column=None, id_column=None):\n",
    "        \"\"\"Initialize model with optional column detection\"\"\"\n",
    "        self.target_column = target_column\n",
    "        self.id_column = id_column\n",
    "        self.label_encoders = {}\n",
    "        self.scaler = StandardScaler()\n",
    "        self.trained_models = None\n",
    "\n",
    "    def auto_detect_columns(self):\n",
    "        \"\"\"Automatically detect target and ID columns based on keywords\"\"\"\n",
    "        if self.target_column is None:\n",
    "            for col in self.df.columns:\n",
    "                if 'leukemia' in col.lower() and 'status' in col.lower():\n",
    "                    self.target_column = col\n",
    "                    print(f\"Detected target column: {self.target_column}\")\n",
    "                    break\n",
    "            if self.target_column is None:\n",
    "                raise ValueError(\"Unable to detect target column related to leukemia status. Please specify it explicitly.\")\n",
    "\n",
    "        if self.id_column is None:\n",
    "            for col in self.df.columns:\n",
    "                if 'id' in col.lower():\n",
    "                    self.id_column = col\n",
    "                    print(f\"Detected ID column: {self.id_column}\")\n",
    "                    break\n",
    "\n",
    "    def load_data(self, data_path=None):\n",
    "        \"\"\"Load data and detect columns if necessary\"\"\"\n",
    "        if data_path is not None:\n",
    "            if data_path.endswith('.csv'):\n",
    "                self.df = pd.read_csv(data_path)\n",
    "            elif data_path.endswith('.xlsx'):\n",
    "                self.df = pd.read_excel(data_path)\n",
    "            elif data_path.endswith('.json'):\n",
    "                self.df = pd.read_json(data_path)\n",
    "            else:\n",
    "                raise ValueError(\"Unsupported file format. Please provide a CSV, Excel, or JSON file.\")\n",
    "        else:\n",
    "            raise ValueError(\"data_path must be provided\")\n",
    "\n",
    "        # Automatically detect target and ID columns if not provided\n",
    "        self.auto_detect_columns()\n",
    "\n",
    "        # Handle missing values\n",
    "        if self.df.isnull().sum().sum() > 0:\n",
    "            self.df.fillna(self.df.mean(numeric_only=True), inplace=True)\n",
    "            self.df.fillna('Unknown', inplace=True)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def explore_data(self, max_plots=6):\n",
    "        \"\"\"Explore data with automatic feature type detection\"\"\"\n",
    "        print(\"\\nClass Distribution for\", self.target_column)\n",
    "        print(self.df[self.target_column].value_counts(normalize=True))\n",
    "        \n",
    "        # Convert target to numerical if it's categorical\n",
    "        if self.df[self.target_column].dtype == 'object':\n",
    "            target_encoder = LabelEncoder()\n",
    "            self.df[self.target_column] = target_encoder.fit_transform(self.df[self.target_column])\n",
    "            print(\"\\nConverted target values:\")\n",
    "            for i, label in enumerate(target_encoder.classes_):\n",
    "                print(f\"{label} -> {i}\")\n",
    "        \n",
    "        # Automatically identify numerical and categorical columns\n",
    "        self.numerical_features = self.df.select_dtypes(\n",
    "            include=['int64', 'float64']).columns.tolist()\n",
    "        self.categorical_features = self.df.select_dtypes(\n",
    "            include=['object', 'category']).columns.tolist()\n",
    "        \n",
    "        # Remove target and ID columns from features\n",
    "        for col in [self.target_column, self.id_column]:\n",
    "            if col in self.numerical_features:\n",
    "                self.numerical_features.remove(col)\n",
    "            if col in self.categorical_features:\n",
    "                self.categorical_features.remove(col)\n",
    "        \n",
    "        print(\"\\nNumerical features:\", self.numerical_features)\n",
    "        print(\"Categorical features:\", self.categorical_features)\n",
    "        \n",
    "        # Plot distributions of numerical features\n",
    "        if len(self.numerical_features) > 0:\n",
    "            n_plots = min(len(self.numerical_features), max_plots)\n",
    "            plt.figure(figsize=(15, 10))\n",
    "            for i, feature in enumerate(self.numerical_features[:n_plots], 1):\n",
    "                plt.subplot(2, 3, i)\n",
    "                sns.histplot(data=self.df, x=feature, hue=self.target_column, multiple=\"stack\")\n",
    "                plt.title(f'Distribution of {feature}')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "        # Correlation matrix\n",
    "        if len(self.numerical_features) > 0:\n",
    "            numerical_df = self.df[self.numerical_features + [self.target_column]]\n",
    "            plt.figure(figsize=(12, 8))\n",
    "            sns.heatmap(numerical_df.corr(), annot=True, cmap='coolwarm', center=0)\n",
    "            plt.title('Correlation Matrix')\n",
    "            plt.show()\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def preprocess_data(self, test_size=0.2, random_state=42):\n",
    "        \"\"\"Preprocess data with automatic handling of different data types\"\"\"\n",
    "        df_processed = self.df.copy()\n",
    "        \n",
    "        # Encode categorical variables\n",
    "        for feature in self.categorical_features:\n",
    "            self.label_encoders[feature] = LabelEncoder()\n",
    "            df_processed[feature] = self.label_encoders[feature].fit_transform(df_processed[feature])\n",
    "        \n",
    "        # Prepare features and target\n",
    "        exclude_cols = [col for col in [self.target_column, self.id_column] if col is not None]\n",
    "        X = df_processed.drop(exclude_cols, axis=1).values\n",
    "        y = df_processed[self.target_column].values\n",
    "        \n",
    "        # Split the data\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(\n",
    "            X, y, test_size=test_size, random_state=random_state\n",
    "        )\n",
    "        \n",
    "        # Scale the features\n",
    "        self.X_train_scaled = self.scaler.fit_transform(self.X_train)\n",
    "        self.X_test_scaled = self.scaler.transform(self.X_test)\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def train_models(self):\n",
    "        \"\"\"Train multiple models with progress updates\"\"\"\n",
    "        self.models = {\n",
    "            'Logistic Regression': LogisticRegression(max_iter=1000),\n",
    "            'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "        }\n",
    "        \n",
    "        self.trained_models = {}\n",
    "        for name, model in self.models.items():\n",
    "            print(f\"\\nTraining {name}...\")\n",
    "            model.fit(self.X_train_scaled, self.y_train)\n",
    "            train_score = model.score(self.X_train_scaled, self.y_train)\n",
    "            print(f\"{name} training accuracy: {train_score:.4f}\")\n",
    "            self.trained_models[name] = model\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def evaluate_models(self):\n",
    "        \"\"\"Evaluate models with detailed metrics\"\"\"\n",
    "        self.results = {}\n",
    "        \n",
    "        for name, model in self.trained_models.items():\n",
    "            print(f\"\\nEvaluating {name}...\")\n",
    "            y_pred = model.predict(self.X_test_scaled)\n",
    "            y_pred_proba = model.predict_proba(self.X_test_scaled)[:, 1]\n",
    "            \n",
    "            accuracy = accuracy_score(self.y_test, y_pred)\n",
    "            fpr, tpr, _ = roc_curve(self.y_test, y_pred_proba)\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "            \n",
    "            self.results[name] = {\n",
    "                'accuracy': accuracy,\n",
    "                'fpr': fpr,\n",
    "                'tpr': tpr,\n",
    "                'auc': roc_auc,\n",
    "                'predictions': y_pred,\n",
    "                'probabilities': y_pred_proba\n",
    "            }\n",
    "\n",
    "        # Plot ROC curves\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        for name, metrics in self.results.items():\n",
    "            plt.plot(metrics['fpr'], metrics['tpr'], \n",
    "                    label=f'{name} (AUC = {metrics[\"auc\"]:.2f})')\n",
    "        plt.plot([0, 1], [0, 1], 'k--')\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('ROC Curves for All Models')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "        # Print detailed classification reports\n",
    "        for name, metrics in self.results.items():\n",
    "            print(f\"\\nClassification Report for {name}:\")\n",
    "            print(classification_report(self.y_test, metrics['predictions']))\n",
    "\n",
    "        # Compare model accuracies\n",
    "        accuracies = {name: metrics['accuracy'] \n",
    "                     for name, metrics in self.results.items()}\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.bar(accuracies.keys(), accuracies.values())\n",
    "        plt.title('Model Accuracy Comparison')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def _load_data_from_path(self, data_path):\n",
    "        \"\"\"Helper method to load data from a file path.\"\"\"\n",
    "        if data_path.endswith('.csv'):\n",
    "            return pd.read_csv(data_path)\n",
    "        elif data_path.endswith('.xlsx'):\n",
    "            return pd.read_excel(data_path)\n",
    "        elif data_path.endswith('.json'):\n",
    "            return pd.read_json(data_path)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported file format. Please provide a CSV, Excel, or JSON file.\")\n",
    "\n",
    "    def predict_unlabeled_data(self, user_input):\n",
    "        \"\"\"Predict leukemia status for user-provided input.\"\"\"\n",
    "        # Align user input with training features\n",
    "        aligned_input = [user_input[feature] for feature in self.numerical_features + self.categorical_features]\n",
    "\n",
    "        # Scale numerical features\n",
    "        aligned_input_scaled = self.scaler.transform([aligned_input])\n",
    "\n",
    "        # Use the trained model to predict\n",
    "        predictions = {name: model.predict(aligned_input_scaled)[0] for name, model in self.trained_models.items()}\n",
    "\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c2ed1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and run the model with automatic column detection\n",
    "model = LeukemiaDetectionModel()\n",
    "\n",
    "model.load_data(\n",
    "    data_path='biased_leukemia_dataset.csv'  # Replace with your data file path\n",
    ")\n",
    "\n",
    "model.explore_data()\n",
    "\n",
    "model.preprocess_data(test_size=0.2)\n",
    "\n",
    "model.train_models()\n",
    "\n",
    "model.evaluate_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77caec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict leukemia status for a new dataset using user input\n",
    "def get_user_input():\n",
    "    \"\"\"Prompt user for input with feature ranges and return a dictionary.\"\"\"\n",
    "    print(\"\\nPlease provide the following inputs:\")\n",
    "    user_data = {}\n",
    "    for feature in model.numerical_features + model.categorical_features:\n",
    "        instruction = \"\"\n",
    "        if feature in model.numerical_features:\n",
    "            min_val = model.df[feature].min()\n",
    "            max_val = model.df[feature].max()\n",
    "            instruction = f\"(Numerical: Range [{min_val}, {max_val}])\"\n",
    "            value = float(input(f\"Enter value for {feature} {instruction}: \"))\n",
    "        elif feature in model.categorical_features:\n",
    "            unique_vals = model.df[feature].unique()\n",
    "            instruction = f\"(Categorical: Possible values {list(unique_vals)})\"\n",
    "            value = input(f\"Enter value for {feature} {instruction}: \")\n",
    "            # Encode categorical input using the label encoder\n",
    "            if feature in model.label_encoders:\n",
    "                value = model.label_encoders[feature].transform([value])[0]\n",
    "        user_data[feature] = value\n",
    "    return user_data\n",
    "\n",
    "# Get user input and make predictions\n",
    "user_input = get_user_input()\n",
    "predictions = model.predict_unlabeled_data(user_input)\n",
    "\n",
    "# Convert predictions to human-readable labels\n",
    "for model_name, prediction in predictions.items():\n",
    "    result = \"Has Leukemia\" if prediction == 1 else \"Does Not Have Leukemia\"\n",
    "    print(f\"\\nPrediction from {model_name}: {result}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
